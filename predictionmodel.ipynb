{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/c1kjpy9d04l0bqlg_b7cclmw0000gn/T/ipykernel_89494/1544173623.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataset is in a CSV file named 'emnist-balanced-train.csv'\n",
    "csv_file_path = 'emnist-balanced-train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(csv_file_path, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (X) and labels (y)\n",
    "X = df.iloc[:, 1:].values  # Assuming pixel values start from the second column\n",
    "y = df.iloc[:, 0].values   # Assuming labels are in the first column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features to (num_samples, image_height, image_width, num_channels)\n",
    "image_height = 28\n",
    "image_width = 28\n",
    "X = X.reshape(-1, image_height, image_width, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical values using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of classes\n",
    "num_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to the range [0, 1]\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convolutional block\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second convolutional block\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third convolutional block\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Average Pooling\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layers\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 26, 26, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 11, 11, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 3, 3, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 128)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               66048     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 47)                24111     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183727 (717.68 KB)\n",
      "Trainable params: 183279 (715.93 KB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1410/1410 [==============================] - 26s 18ms/step - loss: 1.5398 - accuracy: 0.5374 - val_loss: 0.6346 - val_accuracy: 0.7801\n",
      "Epoch 2/20\n",
      "1410/1410 [==============================] - 24s 17ms/step - loss: 0.8852 - accuracy: 0.7076 - val_loss: 0.5416 - val_accuracy: 0.8130\n",
      "Epoch 3/20\n",
      "1410/1410 [==============================] - 24s 17ms/step - loss: 0.7885 - accuracy: 0.7368 - val_loss: 0.5032 - val_accuracy: 0.8237\n",
      "Epoch 4/20\n",
      "1410/1410 [==============================] - 24s 17ms/step - loss: 0.7345 - accuracy: 0.7546 - val_loss: 0.4801 - val_accuracy: 0.8313\n",
      "Epoch 5/20\n",
      "1410/1410 [==============================] - 24s 17ms/step - loss: 0.6984 - accuracy: 0.7641 - val_loss: 0.4626 - val_accuracy: 0.8381\n",
      "Epoch 6/20\n",
      "1410/1410 [==============================] - 23s 16ms/step - loss: 0.6750 - accuracy: 0.7705 - val_loss: 0.4620 - val_accuracy: 0.8369\n",
      "Epoch 7/20\n",
      "1410/1410 [==============================] - 22s 16ms/step - loss: 0.6515 - accuracy: 0.7784 - val_loss: 0.4452 - val_accuracy: 0.8425\n",
      "Epoch 8/20\n",
      "1410/1410 [==============================] - 22s 16ms/step - loss: 0.6364 - accuracy: 0.7834 - val_loss: 0.4325 - val_accuracy: 0.8464\n",
      "Epoch 9/20\n",
      "1410/1410 [==============================] - 23s 16ms/step - loss: 0.6235 - accuracy: 0.7874 - val_loss: 0.4234 - val_accuracy: 0.8510\n",
      "Epoch 10/20\n",
      "1410/1410 [==============================] - 22s 16ms/step - loss: 0.6065 - accuracy: 0.7921 - val_loss: 0.4370 - val_accuracy: 0.8468\n",
      "Epoch 11/20\n",
      "1410/1410 [==============================] - 22s 16ms/step - loss: 0.5990 - accuracy: 0.7936 - val_loss: 0.4317 - val_accuracy: 0.8471\n",
      "Epoch 12/20\n",
      "1410/1410 [==============================] - 23s 16ms/step - loss: 0.5937 - accuracy: 0.7951 - val_loss: 0.4192 - val_accuracy: 0.8520\n",
      "Epoch 13/20\n",
      "1410/1410 [==============================] - 23s 17ms/step - loss: 0.5840 - accuracy: 0.7979 - val_loss: 0.4159 - val_accuracy: 0.8538\n",
      "Epoch 14/20\n",
      "1410/1410 [==============================] - 23s 16ms/step - loss: 0.5703 - accuracy: 0.8028 - val_loss: 0.4207 - val_accuracy: 0.8519\n",
      "Epoch 15/20\n",
      "1410/1410 [==============================] - 23s 16ms/step - loss: 0.5686 - accuracy: 0.8032 - val_loss: 0.4114 - val_accuracy: 0.8558\n",
      "Epoch 16/20\n",
      "1410/1410 [==============================] - 23s 17ms/step - loss: 0.5620 - accuracy: 0.8060 - val_loss: 0.4163 - val_accuracy: 0.8533\n",
      "Epoch 17/20\n",
      "1410/1410 [==============================] - 24s 17ms/step - loss: 0.5552 - accuracy: 0.8070 - val_loss: 0.4074 - val_accuracy: 0.8551\n",
      "Epoch 18/20\n",
      "1410/1410 [==============================] - 24s 17ms/step - loss: 0.5494 - accuracy: 0.8110 - val_loss: 0.4106 - val_accuracy: 0.8563\n",
      "Epoch 19/20\n",
      "1410/1410 [==============================] - 23s 17ms/step - loss: 0.5493 - accuracy: 0.8082 - val_loss: 0.3986 - val_accuracy: 0.8574\n",
      "Epoch 20/20\n",
      "1410/1410 [==============================] - 24s 17ms/step - loss: 0.5440 - accuracy: 0.8112 - val_loss: 0.4122 - val_accuracy: 0.8525\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X, y, epochs=20, validation_split=0.2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/andrewasher/Education/Medicine_Prescription/Untitled-1.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrewasher/Education/Medicine_Prescription/Untitled-1.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andrewasher/Education/Medicine_Prescription/Untitled-1.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_loss, test_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrewasher/Education/Medicine_Prescription/Untitled-1.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_accuracy\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a HDF5 file\n",
    "model.save('medicine_prediction.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test_file_path = '/Users/andrewasher/Education/Medicine_Prescription/emnist-balanced-test.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(csv_test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shuffle the test dataset\n",
    "df_test = shuffle(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (X_test) and labels (y_test)\n",
    "X_test = df_test.iloc[:, 1:].values  # Assuming pixel values start from the second column\n",
    "y_test = df_test.iloc[:, 0].values   # Assuming labels are in the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features to (num_samples, image_height, image_width, num_channels)\n",
    "X_test = X_test.reshape(-1, image_height, image_width, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical values using LabelEncoder\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588/588 [==============================] - 2s 3ms/step - loss: 0.4315 - accuracy: 0.8480\n",
      "Test Accuracy: 84.80%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your trained character recognition model\n",
    "model_path = 'medicine_prediction.h5'  # Replace with the path to your saved model file\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    # Step 1: Loading and Resizing\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (28, 28))  # Resize to match the expected input dimensions of the model\n",
    "\n",
    "    # Step 2: Grayscale Conversion\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Step 3: Image Processing\n",
    "    processed_image = preprocess_image(gray_image)\n",
    "\n",
    "    # Step 4: Thresholding\n",
    "    _, thresholded_image = cv2.threshold(processed_image, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Step 5: Contour Detection\n",
    "    contours, _ = cv2.findContours(thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Step 6: Cropping & Character Recognition\n",
    "    recognized_text = recognize_characters(gray_image, contours)\n",
    "\n",
    "    return recognized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for image preprocessing\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale if the input image is in color\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Apply adaptive thresholding to improve contrast\n",
    "    _, image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Perform morphological operations (optional)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Resize the image to a consistent size\n",
    "    image = cv2.resize(image, (300, 300))\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for character recognition\n",
    "def recognize_characters(image, contours):\n",
    "    recognized_text = \"\"\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        character_image = image[y:y+h, x:x+w]\n",
    "\n",
    "        # Apply your character recognition model here (similar to the CNN model training)\n",
    "        character_prediction = np.argmax(model.predict(np.expand_dims(character_image, axis=0)))\n",
    "\n",
    "        # Append the recognized character to the result\n",
    "        recognized_text += get_character_from_prediction(character_prediction)\n",
    "\n",
    "    return recognized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the recognized character from the model prediction\n",
    "def get_character_from_prediction(prediction):\n",
    "    # Assuming predictions are integers corresponding to character ASCII codes\n",
    "    recognized_character = str(chr(prediction + 65))  # Assumes predictions are integers (A-Z)\n",
    "    \n",
    "    # You might need to adjust this logic based on your actual output\n",
    "    return recognized_character\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n",
      "L\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "image_path = '/Users/andrewasher/Education/Medicine_Prescription/image.jpeg'  # Replace with the path to your input image\n",
    "result = process_image(image_path)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
